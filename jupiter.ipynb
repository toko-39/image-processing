{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import mnist \n",
    "import matplotlib.pyplot as plt\n",
    "# import sys\n",
    "\n",
    "# データの読み込み\n",
    "train_images = mnist.download_and_parse_mnist_file(\"/mnt/c/Users/Owner/Downloads/train-images-idx3-ubyte.gz\")\n",
    "train_labels = mnist.download_and_parse_mnist_file(\"/mnt/c/Users/Owner/Downloads/train-labels-idx1-ubyte.gz\")\n",
    "test_images = mnist.download_and_parse_mnist_file(\"/mnt/c/Users/Owner/Downloads/t10k-images-idx3-ubyte.gz\")\n",
    "test_labels = mnist.download_and_parse_mnist_file(\"/mnt/c/Users/Owner/Downloads/t10k-labels-idx1-ubyte.gz\")\n",
    "\n",
    "# # --- ユーザー入力と前処理 ---\n",
    "# def get_input_image_vector():\n",
    "#     # ユーザーから画像番号を入力させ、対応する画像ベクトルを返す\n",
    "#     try:\n",
    "#         image_number = int(input(\"0~9999までの整数を入力してください：\"))\n",
    "#         if not (0 <= image_number <= 9999):\n",
    "#             print(\"無効な数値です。\")\n",
    "#             sys.exit()\n",
    " \n",
    "#         # 28x28の画像を1次元ベクトルに変換\n",
    "#         return train_images[image_number].reshape(-1)\n",
    "#     except ValueError:\n",
    "#         print(\"無効な入力です。整数を入力してください。\")\n",
    "#         sys.exit()\n",
    "\n",
    "# def get_random_index(batch_size): #インデックスをランダムに取得\n",
    "#     # np.arangeの生成を省略し、直接データ数からサンプリングする\n",
    "#     return np.random.choice(len(train_images), size=batch_size, replace=False)\n",
    "\n",
    "def get_shaffled_index():\n",
    "    index = np.arange(len(train_images)) # 0から始まるインデックスの配列を作成\n",
    "    np.random.shuffle(index) # インデックスをシャッフル\n",
    "    return index\n",
    "\n",
    "# 画像とラベルを別々に取得する冗長な関数を一つに統合\n",
    "def get_batch(random_index): \n",
    "    # ベクトルとラベルをまとめて取得\n",
    "    batch_images = train_images[random_index].reshape(len(random_index), -1) # 画像データを (バッチサイズ, 784) の2次元配列に変換\n",
    "    batch_labels = train_labels[random_index]\n",
    "    return batch_images, batch_labels\n",
    "\n",
    "def get_one_hot_label(batch_labels, output_layer_size):\n",
    "    one_hot_labels = np.zeros((batch_labels.size, output_layer_size)) # ゼロで満たされた配列を作成\n",
    "    one_hot_labels[np.arange(batch_labels.size), batch_labels] = 1 # 各行の、正解ラベルに対応するインデックスを1にする\n",
    "    return one_hot_labels\n",
    "\n",
    "\n",
    "np.random.seed(777) # シードを固定\n",
    "\n",
    "# レイヤーの次元数を定義\n",
    "input_size = train_images[0].size  # 入力層: 784 (28*28)\n",
    "hidden_layer_size = 100 # 中間層: 100ユニット\n",
    "output_layer_size = 10  # 出力層: 10ユニット (0-9の数字に対応)\n",
    "\n",
    "# 重みとバイアスを正規分布で初期化\n",
    "\n",
    "is_load = str(input('ロードしますか？ yes or no:  '))\n",
    "if is_load == 'yes' :\n",
    "    loaded_data = np.load('assignment3_parameter.npz')\n",
    "    weight1 = loaded_data['weight1']\n",
    "    bias1 = loaded_data['bias1']\n",
    "    weight2 = loaded_data['weight2']\n",
    "    bias2 = loaded_data['bias2']\n",
    "else:\n",
    "    # 第1層（入力層 -> 中間層）\n",
    "    weight1 = np.random.normal(loc=0.0, scale=np.sqrt(1 / input_size), size=(hidden_layer_size, input_size)) # weight1: (100, 784) 784個の入力それぞれに対する、100個の中間層ユニットの重み\n",
    "    bias1 = np.random.normal(loc=0.0, scale=np.sqrt(1 / input_size), size=hidden_layer_size) # bias1: (100,) 100個の中間層ユニットのバイアス\n",
    "\n",
    "    # 第2層（中間層 -> 出力層）\n",
    "    weight2 = np.random.normal(loc=0.0, scale=np.sqrt(1 / hidden_layer_size), size=(output_layer_size, hidden_layer_size)) # weight2: (10, 100) 100個の中間層ユニットそれぞれに対する、10個の出力層ユニットの重み\n",
    "    bias2 = np.random.normal(loc=0.0, scale=np.sqrt(1 / hidden_layer_size), size=output_layer_size) # bias2: (10,) 10個の出力層ユニットのバイアス\n",
    "\n",
    "# --- 活性化関数と出力関数 ---\n",
    "def sigmoid(x):\n",
    "    \"\"\"シグモイド活性化関数\"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"\n",
    "    ソフトマックス関数（オーバーフロー対策版）\n",
    "    各要素を0から1の間の確率に変換\n",
    "    \"\"\"\n",
    "    alpha = np.max(x, axis=-1, keepdims=True)\n",
    "    exp_x = np.exp(x - alpha)\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "# --- 順伝播の実行(重みを更新) ---\n",
    "def forward_propagation(input_vector, weight1, bias1, weight2, bias2):\n",
    "    \n",
    "    # 中間層の計算: 活性化関数の入力　 (バッチサイズ, 784) @ (784, 100) -> (バッチサイズ, 100)\n",
    "    hidden_layer_input = np.dot(input_vector, weight1.T) + bias1\n",
    "    \n",
    "    # 中間層の出力: 活性化関数を適用\n",
    "    hidden_layer_output = sigmoid(hidden_layer_input)\n",
    "    \n",
    "    # 出力層の計算: 活性化関数の入力　(バッチサイズ, 100) @ (100, 10) -> (バッチサイズ, 10)\n",
    "    output_layer_input = np.dot(hidden_layer_output, weight2.T) + bias2\n",
    "    \n",
    "    # 出力層の出力: ソフトマックスを適用して確率を算出\n",
    "    final_output = softmax(output_layer_input)\n",
    "    \n",
    "    return final_output, hidden_layer_output # hidden 追加\n",
    "\n",
    "def get_predicted_class(output_probabilities):\n",
    " # 出力された確率から最も高い確率を持つクラス（予測結果）を取得\n",
    "    if output_probabilities.ndim == 1:\n",
    "        return np.argmax(output_probabilities)\n",
    "    else:\n",
    "        return np.argmax(output_probabilities, axis=1)\n",
    "\n",
    "def get_cross_entropy_error(y_pred, y_true):\n",
    "    \n",
    "    delta = 1e-7\n",
    "    \n",
    "    loss = -np.sum(y_true * np.log(y_pred + delta)) # logの中身が0にならないようにdeltaを導入\n",
    "    \n",
    "    # ミニバッチサイズBで割って平均を求める\n",
    "    batch_size = y_pred.shape[0]\n",
    "    \n",
    "    cross_entropy_error = loss / batch_size\n",
    "    \n",
    "    return cross_entropy_error\n",
    "\n",
    "def backward_propagation_and_update(batch_image_vector, hidden_layer_output, output_probabilities, one_hot_labels, \n",
    "                                    weight1, bias1, weight2, bias2, learning_rate):\n",
    "    \"\"\"\n",
    "    逆伝播法を用いて勾配を計算し、全パラメータを更新する関数。\n",
    "    更新後のパラメータを返す。\n",
    "    \"\"\"\n",
    "    current_batch_size = batch_image_vector.shape[0]\n",
    "    \n",
    "    # --- 逆伝播 ---\n",
    "    dEn_dak = (output_probabilities - one_hot_labels) / current_batch_size\n",
    "    dEn_dX = np.dot(dEn_dak, weight2)\n",
    "    dEn_dW_1 = np.dot(dEn_dak.T, hidden_layer_output)\n",
    "    dEn_db_1 = np.sum(dEn_dak, axis = 0)\n",
    "    dEn_dX_sig = dEn_dX * (hidden_layer_output * (1 - hidden_layer_output))\n",
    "    dEn_dW_2= np.dot(dEn_dX_sig.T, batch_image_vector)\n",
    "    dEn_db_2 = np.sum(dEn_dX_sig, axis=0)\n",
    "\n",
    "    # --- パラメータ更新 ---\n",
    "    weight1 -= dEn_dW_2 * learning_rate \n",
    "    bias1   -= dEn_db_2 * learning_rate\n",
    "    weight2 -= dEn_dW_1 * learning_rate \n",
    "    bias2   -= dEn_db_1 * learning_rate\n",
    "    \n",
    "    return weight1, bias1, weight2, bias2\n",
    "\n",
    "def get_accuracy(y_prop, y_true): # 正答率計算\n",
    "    y_pred = get_predicted_class(y_prop) # 予測結果\n",
    "    accuracy = np.sum(y_pred == y_true) / len(y_prop)\n",
    "    return accuracy\n",
    "\n",
    "def calculate_accuracy(images_vector, labels, weight1, bias1, weight2, bias2):\n",
    "    \"\"\"\n",
    "    指定されたデータセットに対するモデルの正答率を計算する関数。\n",
    "    \"\"\"\n",
    "    #  順伝播で予測確率を計算\n",
    "    probabilities, _ = forward_propagation(images_vector, weight1, bias1, weight2, bias2)\n",
    "    \n",
    "    #  正答率を計算\n",
    "    accuracy = get_accuracy(probabilities, labels)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# --- メイン処理 ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    batch_size = 100\n",
    "    epoch_number = 10\n",
    "    learning_rate = 0.01\n",
    "    train_loss_list, train_acc_list, test_acc_list = [], [], []\n",
    "    \n",
    "    for i in range(1, epoch_number + 1):\n",
    "        error_sum = 0\n",
    "        train_accuracy_sum = 0\n",
    "        shaffled_index = get_shaffled_index()\n",
    "        \n",
    "        for j in range(0, len(shaffled_index), batch_size): # range(start, stop, step) を使い、batch_sizeずつインデックスをずらしながらループ\n",
    "            \n",
    "            #シャッフルしたインデックスから、先頭のbatch_size分取り出す\n",
    "            index = shaffled_index[j:j + batch_size]\n",
    "\n",
    "            # 統合した関数を使い、ミニバッチと対応ラベルを一度に取得\n",
    "            batch_image_vector, batch_labels = get_batch(index)\n",
    "\n",
    "            # 順伝播を実行\n",
    "            output_probabilities, hidden_layer_output = forward_propagation(\n",
    "                batch_image_vector, weight1, bias1, weight2, bias2\n",
    "            )\n",
    "            # one-hot labelsを取得\n",
    "            one_hot_labels = get_one_hot_label(batch_labels, output_layer_size)\n",
    "\n",
    "            \n",
    "            # クロスエントロピー誤差平均を計算\n",
    "            calculated_error = get_cross_entropy_error(output_probabilities, one_hot_labels)\n",
    "            error_sum += calculated_error\n",
    "            \n",
    "            # --- 逆伝播 ---\n",
    "            weight1, bias1, weight2, bias2 = backward_propagation_and_update(\n",
    "                batch_image_vector, hidden_layer_output, output_probabilities, one_hot_labels,\n",
    "                weight1, bias1, weight2, bias2, learning_rate\n",
    "            )\n",
    "\n",
    "            train_accuracy_sum += calculate_accuracy(batch_image_vector, batch_labels, weight1, bias1, weight2, bias2)\n",
    "            \n",
    "        test_accuracy = calculate_accuracy(test_images.reshape(len(test_images), -1), test_labels, weight1, bias1, weight2, bias2)\n",
    "        \n",
    "        num_batches = len(train_images) // batch_size\n",
    "        train_loss_list.append(error_sum / num_batches)\n",
    "        train_acc_list.append(train_accuracy_sum / num_batches)\n",
    "        test_acc_list.append(test_accuracy)\n",
    "        print(f\"{i}エポック目\")\n",
    "        print(f\"  平均クロスエントロピー誤差: {error_sum / num_batches}\")\n",
    "        print(f\"  テストデータに対する正答率: {test_accuracy}\") \n",
    "        print(f\"  学習データに対する正答率: {train_accuracy_sum / num_batches}\")\n",
    "        \n",
    "    # --- グラフの描画 ---\n",
    "    x = np.arange(1, epoch_number + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # 誤差のグラフ\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, train_loss_list, marker='o')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # 正答率のグラフ\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, train_acc_list, marker='o', label='Train Accuracy')\n",
    "    plt.plot(x, test_acc_list, marker='s', label='Test Accuracy')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    np.savez('assignment3_parameter.npz', weight1 = weight1, bias1 = bias1, weight2 = weight2, bias2 = bias2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
